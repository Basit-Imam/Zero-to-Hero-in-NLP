{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import nltk\n",
    "# ^^^ pyforest auto-imports - don't write above this line\n",
    "<h4>Unit 3 <h1 style=\"text-align:center\"> Chapter 3</h1>\n",
    " \n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Naive Bayes Classifiers are **Bayesian** classifiers that make an assumption that the features are **naive** i.e. the features(here words) are independent and have no relation between each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, consider the sentence,\n",
    "\n",
    "'He is my friend. His name is John.'\n",
    "\n",
    "A naive classifier sees no relation between, **He**, **His**, & **John** (even though there is)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we work on any algorithm, we need to convert our text data to numbers.\n",
    "\n",
    "To convert text into numbers, we need a way to represent each word in our data.\n",
    "\n",
    "In the **bag of words** model, we use frequency as a way of representing text as numbers.\n",
    "\n",
    "There are new & better ways to convert our text data into numbers, like **word2vec**.\n",
    "\n",
    "We will first take a look at the ```bag of words``` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bag of words model, as the name suggests, stores words into an unordered **set**.\n",
    "\n",
    "We use **set** because duplicate words are not allowed, as we are storing their frequency as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words in Python\n",
    "\n",
    "> [Code Courtesy](https://www.geeksforgeeks.org/bag-of-words-bow-model-in-nlp/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's take a sample paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Beans. I was trying to explain to somebody as we were flying in, that’s corn. That’s beans. And they were very impressed at my agricultural knowledge. Please give it up for Amaury once again for that outstanding introduction. I have a bunch of good friends here today, including somebody who I served with, who is one of the finest senators in the country, and we’re lucky to have him, your Senator, Dick Durbin is here. I also noticed, by the way, former Governor Edgar here, who I haven’t seen in a long time, and somehow he has not aged and I have. And it’s great to see you, Governor. I want to thank President Killeen and everybody at the U of I System for making it possible for me to be here today. And I am deeply honored at the Paul Douglas Award that is being given to me. He is somebody who set the path for so much outstanding public service here in Illinois. Now, I want to start by addressing the elephant in the room. I know people are still wondering why I didn’t speak at the commencement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Beans. I was trying to explain to somebody as we were flying in, that’s corn. That’s beans. And they were very impressed at my agricultural knowledge. Please give it up for Amaury once again for that outstanding introduction. I have a bunch of good friends here today, including somebody who I served with, who is one of the finest senators in the country, and we’re lucky to have him, your Senator, Dick Durbin is here. I also noticed, by the way, former Governor Edgar here, who I haven’t seen in a long time, and somehow he has not aged and I have. And it’s great to see you, Governor. I want to thank President Killeen and everybody at the U of I System for making it possible for me to be here today. And I am deeply honored at the Paul Douglas Award that is being given to me. He is somebody who set the path for so much outstanding public service here in Illinois. Now, I want to start by addressing the elephant in the room. I know people are still wondering why I didn’t speak at the commencement.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beans. I was trying to explain to somebody as we were flying in, that’s corn. That’s beans. And they were very impressed at my agricultural knowledge. Please give it up for Amaury once again for that outstanding introduction. I have a bunch of good friends here today, including somebody who I served with, who is one of the finest senators in the country, and we’re lucky to have him, your Senator, Dick Durbin is here. I also noticed, by the way, former Governor Edgar here, who I haven’t seen in a long time, and somehow he has not aged and I have. And it’s great to see you, Governor. I want to thank President Killeen and everybody at the U of I System for making it possible for me to be here today. And I am deeply honored at the Paul Douglas Award that is being given to me. He is somebody who set the path for so much outstanding public service here in Illinois. Now, I want to start by addressing the elephant in the room. I know people are still wondering why I didn’t speak at the commencement.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We will first break the sentences, then convert text to lower case, and remove punctuation and non words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beans.',\n",
       " 'I was trying to explain to somebody as we were flying in, that’s corn.',\n",
       " 'That’s beans.',\n",
       " 'And they were very impressed at my agricultural knowledge.',\n",
       " 'Please give it up for Amaury once again for that outstanding introduction.',\n",
       " 'I have a bunch of good friends here today, including somebody who I served with, who is one of the finest senators in the country, and we’re lucky to have him, your Senator, Dick Durbin is here.',\n",
       " 'I also noticed, by the way, former Governor Edgar here, who I haven’t seen in a long time, and somehow he has not aged and I have.',\n",
       " 'And it’s great to see you, Governor.',\n",
       " 'I want to thank President Killeen and everybody at the U of I System for making it possible for me to be here today.',\n",
       " 'And I am deeply honored at the Paul Douglas Award that is being given to me.',\n",
       " 'He is somebody who set the path for so much outstanding public service here in Illinois.',\n",
       " 'Now, I want to start by addressing the elephant in the room.',\n",
       " 'I know people are still wondering why I didn’t speak at the commencement.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please give it up for Amaury once again for that outstanding introduction.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the dataset has been broken into sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Converting to lower case.\n",
    "\n",
    "But why is it neccessary to convert to lower case?\n",
    "\n",
    "- If we don't convert to lower case then, any two words like ```Going``` and ```going``` will be treated differently, resulting in a large feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_cased_data = [sentence.lower() for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'please give it up for amaury once again for that outstanding introduction.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_cased_data[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Removing non-word characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = [re.sub(r'\\W+',' ',sentence) for sentence in lower_cased_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'please give it up for amaury once again for that outstanding introduction '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Removing punctuations if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = [re.sub(r'\\s+',' ',sentence) for sentence in cleaned_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'please give it up for amaury once again for that outstanding introduction '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Creating bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import nltk'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word2count = {} \n",
    "for data in cleaned_data: \n",
    "    words = nltk.word_tokenize(data) \n",
    "    for word in words: \n",
    "        if word not in word2count.keys(): \n",
    "            word2count[word] = 1\n",
    "        else: \n",
    "            word2count[word] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a bag of words that has stored frequency with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beans': 2,\n",
       " 'i': 12,\n",
       " 'was': 1,\n",
       " 'trying': 1,\n",
       " 'to': 8,\n",
       " 'explain': 1,\n",
       " 'somebody': 3,\n",
       " 'as': 1,\n",
       " 'we': 2,\n",
       " 'were': 2,\n",
       " 'flying': 1,\n",
       " 'in': 5,\n",
       " 'that': 4,\n",
       " 's': 3,\n",
       " 'corn': 1,\n",
       " 'and': 7,\n",
       " 'they': 1,\n",
       " 'very': 1,\n",
       " 'impressed': 1,\n",
       " 'at': 4,\n",
       " 'my': 1,\n",
       " 'agricultural': 1,\n",
       " 'knowledge': 1,\n",
       " 'please': 1,\n",
       " 'give': 1,\n",
       " 'it': 3,\n",
       " 'up': 1,\n",
       " 'for': 5,\n",
       " 'amaury': 1,\n",
       " 'once': 1,\n",
       " 'again': 1,\n",
       " 'outstanding': 2,\n",
       " 'introduction': 1,\n",
       " 'have': 3,\n",
       " 'a': 2,\n",
       " 'bunch': 1,\n",
       " 'of': 3,\n",
       " 'good': 1,\n",
       " 'friends': 1,\n",
       " 'here': 5,\n",
       " 'today': 2,\n",
       " 'including': 1,\n",
       " 'who': 4,\n",
       " 'served': 1,\n",
       " 'with': 1,\n",
       " 'is': 4,\n",
       " 'one': 1,\n",
       " 'the': 9,\n",
       " 'finest': 1,\n",
       " 'senators': 1,\n",
       " 'country': 1,\n",
       " 're': 1,\n",
       " 'lucky': 1,\n",
       " 'him': 1,\n",
       " 'your': 1,\n",
       " 'senator': 1,\n",
       " 'dick': 1,\n",
       " 'durbin': 1,\n",
       " 'also': 1,\n",
       " 'noticed': 1,\n",
       " 'by': 2,\n",
       " 'way': 1,\n",
       " 'former': 1,\n",
       " 'governor': 2,\n",
       " 'edgar': 1,\n",
       " 'haven': 1,\n",
       " 't': 2,\n",
       " 'seen': 1,\n",
       " 'long': 1,\n",
       " 'time': 1,\n",
       " 'somehow': 1,\n",
       " 'he': 2,\n",
       " 'has': 1,\n",
       " 'not': 1,\n",
       " 'aged': 1,\n",
       " 'great': 1,\n",
       " 'see': 1,\n",
       " 'you': 1,\n",
       " 'want': 2,\n",
       " 'thank': 1,\n",
       " 'president': 1,\n",
       " 'killeen': 1,\n",
       " 'everybody': 1,\n",
       " 'u': 1,\n",
       " 'system': 1,\n",
       " 'making': 1,\n",
       " 'possible': 1,\n",
       " 'me': 2,\n",
       " 'be': 1,\n",
       " 'am': 1,\n",
       " 'deeply': 1,\n",
       " 'honored': 1,\n",
       " 'paul': 1,\n",
       " 'douglas': 1,\n",
       " 'award': 1,\n",
       " 'being': 1,\n",
       " 'given': 1,\n",
       " 'set': 1,\n",
       " 'path': 1,\n",
       " 'so': 1,\n",
       " 'much': 1,\n",
       " 'public': 1,\n",
       " 'service': 1,\n",
       " 'illinois': 1,\n",
       " 'now': 1,\n",
       " 'start': 1,\n",
       " 'addressing': 1,\n",
       " 'elephant': 1,\n",
       " 'room': 1,\n",
       " 'know': 1,\n",
       " 'people': 1,\n",
       " 'are': 1,\n",
       " 'still': 1,\n",
       " 'wondering': 1,\n",
       " 'why': 1,\n",
       " 'didn': 1,\n",
       " 'speak': 1,\n",
       " 'commencement': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
